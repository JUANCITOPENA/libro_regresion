# Pruebas de hipótesis {#ph}
En este capítulo se muestra como realizar pruebas de hipótesis para un modelo de regresión lineal.

## Prueba sobre todos los coeficientes {-}
Cuando se tiene un modelo de regresión con $p$ variables, es usual que nos preguntemos si alguna de las covariables aporta información o si ninguna aporta información, esta duda se puede resumir por medio del siguiente conjunto de hipótesis.

$$H_0: \beta_1 = \beta_2 = \ldots = \beta_p = 0,$$
frente a
$$H_A: \text{al menos algún} \, \beta \, \text{no es cero}$$
Esta prueba de hipótesis se llama prueba de significancia de la regresión. Para realizar esta prueba se puede utilizar la salida del `summary`. La estructura de la función se muestra a continuación.

```{r, eval=FALSE}
summary(object, correlation = FALSE, symbolic.cor = FALSE, ...)
```

Los argumentos de esta función son:

- `object`: un objeto de la clase `lm`.
- `correlation`: parámetro lógico para que se incluya al matriz de correlaciones entre los parámetros, por defecto es `FALSE`.

## Ejemplo {-}
Como ilustración vamos a usar los datos del ejemplo 3.1 del libro de [Montgomery, Peck and Vining (2003)](https://www.amazon.com/Introduccion-analisis-regresion-lineal-Spanish/dp/9702403278). En el ejemplo 3.1 los autores ajustaron un modelo de regresión lineal múltiple para explicar el __Tiempo__ necesario para que un trabajador haga el mantenimiento y surta una máquina dispensadora de refrescos en función de las variables __Número de Cajas__ y __Distancia__.

¿Son las variables número de cajas y distancia significativas para explicar el tiempo medio?

En este ejemplo nos interesa probar $H_0: \beta_{cant} = \beta_{dist} = 0,$ frente a $H_A: \text{al menos algún} \, \beta \, \text{no es cero}$.

Los datos para el ejemplo están disponibles en el paquete **MPV** [@R-MPV] dentro del objeto `softdrink`. A continuación el código para disponer los datos, ajustar el modelo y mostrar la tabla de resumen con `summary`.

```{r, message=FALSE}
require(MPV)
colnames(softdrink) <- c('tiempo', 'cantidad', 'distancia')
mod <- lm(tiempo ~ cantidad + distancia, data=softdrink)
summary(mod)
```

En la última línea de la salida anterior tenemos la información de la prueba de hipótesis sobre significancia de la regresión. El valor-P de esta prueba es 4.687e-16 y por lo tanto podemos rechazar $H_0$ a un nivel de significancia usual del 5%, eso significa que al menos una de las dos covariables del modelo es significativa para explicar el tiempo medio.

```{block2, type='rmdnote'}
El no rechazar $H_0: \beta_1 = \beta_2 = \ldots = \beta_p = 0$ significa que ninguna de las variables aporta información para explicar la media de $Y$. Lo que se debe hacer luego es buscar nuevas covariables que sean significativas.
```

```{block2, type='rmdnote'}
El rechazar $H_0: \beta_1 = \beta_2 = \ldots = \beta_p = 0$ significa que una, o dos, o tres, o cuatro, ..., o que todas las $p$ covariables son significativas. Pero, ¿cómo saber cuales variables son significativas? 
  La respuesta está en la siguiente sección.
```

## Pruebas sobre los coeficientes $\beta$ {-}
Cuando se tiene un modelo de regresión con $p$ variables, es usual que nos interese estudiar 
$$H_0: \beta_k = \beta_{k0},$$
frente a una de las tres siguientes hipótesis alternas:
$$H_A: \beta_k < \beta_{k0}, \quad H_A: \beta_k \neq \beta_{k0}, \quad H_A: \beta_k  > \beta_{k0},$$
para algún $k=0, 1, 2, \ldots, p$.

```{block2, type='rmdnote'}
Cuando se realiza una prueba de hipótesis sobre uno de los coeficientes $\beta$, se asume que las variables restantes permanecen en el modelo, es decir que este tipo de pruebas son pruebas marginales.
```

## Función `summary` para $\beta_{k0} = 0$  {-}
Para realizar pruebas de hipótesis cuando el valor de referencia $\beta_{k0}$ es igual a cero se puede usar la función `summary`. 

### Ejemplo {-} 
Aquí vamos a retomar el ejemplo 2.1 del libro de [Montgomery, Peck and Vining (2003)](https://www.amazon.com/Introduccion-analisis-regresion-lineal-Spanish/dp/9702403278). En el ejemplo 2.1 los autores ajustaron un modelo de regresión lineal simple para explicar la Resistencia de una soldadura en función de la Edad de la misma.

¿Será la variable Edad una variable significativa para el modelo? es decir, ¿será el coeficiente de la Edad igual a cero o no?

Las anteriores preguntas se pueden resumir por medio del siguiente conjunto de hipótesis.

$$H_0: \beta_{Edad} = 0,$$
$$H_A: \beta_{Edad} \neq 0$$

Para responder a esta pregunta vamos a ajustar el modelo de la forma usual y luego vamos a construir la tabla de resumen del modelo, el código para hacer esto es el siguiente.

```{r}
file <- "https://raw.githubusercontent.com/fhernanb/datos/master/propelente"
datos <- read.table(file=file, header=TRUE)
mod <- lm(Resistencia ~ Edad, data=datos)
summary(mod)
```

De la tabla anterior tenemos que el valor-P asociado a Edad es 1.64e-10, por lo tanto a un nivel de significancia usual de 5%, hay evidencias para rechazar $H_0$ y se concluye que la variable Edad si aporta información para predecir la media de la Resistencia. 

## Función `beta_test` para $\beta_{k0} \neq 0$ {-}
Para realizar pruebas de hipótesis cuando el valor de referencia $\beta_{k0}$ es diferente de cero, se puede usar la función `beta_test` del paquete **model** [@R-model]. Este paquete está alojado en github y para poder instalarlo se sebe usar el siguiente código.

```{r eval=FALSE}
if (!require('devtools')) install.packages('devtools')
devtools::install_github('fhernanb/model', force=TRUE)
```

La estructura de la función se muestra a continuación.

```{r, eval=FALSE}
beta_test(object, alternative = c("two.sided", "less", "greater"), parm, ref.value)
```

Los argumentos de esta función son:

- `object`: un objeto de la clase `lm`.
- `alternative`: una cadena de caracteres indicando el signo de la hipótesis alterna, los valores posibles son `two.sided` (valor por defecto), `greater` o `less`.
- `parm`: vector con el nombre de la variable.
- `ref.value`: valor de referencia $\beta_{k0}$ de la prueba.

### Ejemplo {-} 
Aquí vamos a retomar el ejemplo 2.1 del libro de [Montgomery, Peck and Vining (2003)](https://www.amazon.com/Introduccion-analisis-regresion-lineal-Spanish/dp/9702403278). En el ejemplo 2.1 los autores ajustaron un modelo de regresión lineal simple para explicar la Resistencia de una soldadura en función de la Edad de la misma.

El proveedor de la soldadura afirma que la resistencia media para soldaduras nuevas es 2700 psi. Pruebe la hipótesis de que la resistencia media es diferente a un nivel de significancia del 5%.

La anterior pregunta se pueden resumir por medio del siguiente conjunto de hipótesis.

$$H_0: \beta_{0} = 2700,$$
$$H_A: \beta_{0} \neq 2700$$

Para responder a esta pregunta vamos usar la función `beta_test`.

```{r}
library(model)
beta_test(object=mod, parm='(Intercept)', ref.value=2700, alternative='two.sided')
```

Como el valor-P obtenido es 0.1197, entonces la resistencia media para soldaduras nuevas sigue siendo de 2700 psi, en otras palabras, no hay evidencias para rechazar $H_0$, esto a un nivel de significancia del 5%.

## Función `anova` {-}
Las utilidades de la función `anova` son: 

- comparar modelos anidados. 
- comparar las variables de un modelo.

Suponga que se tienen dos modelos `m1` y `m2` creados para explicar la misma variable respuesta. El modelo `m1` se dice que está anidado en el modelo `m2` si, el modelo `m2` tiene todos los términos de `m1` y al menos otro término que no esté en `m1`.

El método S3 `anova.lm` (o simplemente `anova`) tiene la estructura mostrada a continuación.

```{r, eval=FALSE}
anova(object, test, scale=0)
```

Los argumentos de esta función son:

- `object`: un objeto de la clase `lm`.
- `test`: una cadena de caracteres indicando el tipo de prueba, `F`, `Chisq` o `Cp`, el valor por defecto es `F`.
- `scale`: valor de la estimación de $\sigma^2$. Cuando es igual a cero se usa el estimador del modelo con más parámetros (`m2`).

### Ejemplo {-}
En este ejemplo queremos comparar dos modelos anidados, el modelo `m1` con la fórmula `y ~ x1 + x2` y el modelo `m2` con la fórmula `y ~ x1 + x2 + x3 + x4`. 

¿Será que la inclusión simultánea de las variables `x3` y `x4` mejora el modelo para explicar la variable respuesta `y`?

Para este ejemplo vamos a usar los datos que se muestran a continuación.

```{r}
datos <- structure(list(y = c(29.5, 27.9, 25.9, 29.9, 29.9, 30.9, 28.9, 
35.9, 31.5, 31, 30.9, 30, 36.9, 41.9, 40.5, 43.9, 37.5, 37.9, 
44.5, 37.9, 38.9, 36.9, 45.8, 25.9), x1 = c(5.0208, 4.5429, 4.5573, 
5.0597, 3.891, 5.898, 5.6039, 5.8282, 5.3003, 6.2712, 5.9592, 
5.05, 8.2464, 6.6969, 7.7841, 9.0384, 5.9894, 7.5422, 8.7951, 
6.0831, 8.3607, 8.14, 9.1416, 4.9176), x2 = c(1, 1, 1, 1, 1, 
1, 1, 1, 1, 1, 1, 1, 1.5, 1.5, 1.5, 1, 1, 1.5, 1.5, 1.5, 1.5, 
1, 1.5, 1), x3 = c(3.531, 2.275, 4.05, 4.455, 4.455, 5.85, 9.52, 
6.435, 4.9883, 5.52, 6.666, 5, 5.15, 6.902, 7.102, 7.8, 5.52, 
5, 9.89, 6.7265, 9.15, 8, 7.3262, 3.472), x4 = c(1.5, 1.175, 
1.232, 1.121, 0.988, 1.24, 1.501, 1.225, 1.552, 0.975, 1.121, 
1.02, 1.664, 1.488, 1.376, 1.5, 1.256, 1.69, 1.82, 1.652, 1.777, 
1.504, 1.831, 0.998)), class = "data.frame", row.names = c("1", 
"2", "3", "4", "5", "6", "7", "8", "9", "10", "11", "12", "13", 
"14", "15", "16", "17", "18", "19", "20", "21", "22", "23", "24"
))
head(datos)
```

Ahora vamos a ajustar ambos modelos usando el siguiente código.

```{r}
mod1 <- lm(y ~ x1 + x2, data=datos)
mod2 <- lm(y ~ x1 + x2 + x3 + x4, data=datos)
```

El objetivo en este ejercicio analizar el siguiente conjunto de hipótesis.

$$H_0: \text{las variables x3 y x4 no mejoran el modelo},$$
$$H_A: \text{al menos una de ellas si mejora el modelo}$$

Para comparar los dos modelos usamos la siguiente instrucción.

```{r}
anova(mod1, mod2)
```

De la salida anterior se observa que el valor-P de la prueba es de 0.7565, usando un nivel de significancia del 5%, se concluye que la inclusión de las variables `x3` y `x4` no mejoran el modelo.

### Ejemplo {-}
En este ejemplo se mostrará la segunda utilidad de la función `anova`. Para esto vamos a utilizar la base de datos `Cars93` del paquete `MASS`. El objetivo es construir un modelo para explicar la media del `Price` de los autos en función de las variables `Horsepower`, `Type` y `Weight`.

La solución de este ejercicio tendrá dos partes, en la primera se construirán varios modelos, iniciando con uno sin covariables (`mod0`) hasta uno con todas las covariables (`mod3`). En la segunda parte se analizará el modelo con todas las covariables directamente.

A continuación el código para crear y comparar los modelos sin covariables y el modelo con solo `Horsepower`.

```{r}
library(MASS)
mod0 <- lm(Price ~ 1, data=Cars93)
mod1 <- lm(Price ~ Horsepower, data=Cars93)
anova(mod0, mod1)
```

De la salida anterior se tiene que el valor-P es < 2.2e-16 y por lo tanto se concluye que la variable `Horsepower` mejora el modelo (la misma conclusión se pudo obtener del `summary`).

Ahora vamos a crear y comparar el modelo con sólo `Horsepower` con el modelo con `Horsepower` y `Type`.

```{r}
mod2 <- lm(Price ~ Horsepower + Type, data=Cars93)
anova(mod1, mod2)
```

De la salida anterior se tiene que el valor-P es 0.01337 y por lo tanto se concluye que el modelo `mod2` con dos covariables explica mejor la variable `Price`.

Ahora vamos a crear y comparar el modelo con `Horsepower` y `Type` con el modelo con las tres covariables.

```{r}
mod3 <- lm(Price ~ Horsepower + Type + Weight, data=Cars93)
anova(mod2, mod3)
```

De esta última salida vemos que el valor-P es 0.648, esto indica que la inclusión de la variable `Weight` no mejora el modelo `mod2` (la misma conclusión se pudo obtener del `summary`).

En esta segunda parte del ejemplo se usará la función `anova` directamente sobre el modelo completo `mod3`, a continuación los resultados.

```{r}
anova(mod3)
```

En la tabla anterior aparecen los resultados de una prueba de hipótesis secuencial a partir de la fórmula de `mod3`. La fórmula de `mod3` es `Price ~ Horsepower + Type + Weight`, por lo tanto en la primera línea de la tabla aparece la variable `Horsepower`, luego en la segunda aparece `Type` y así hasta la última variable `Weight`. El valor-P reportado en la primer línea es < 2e-16, esto indica el modelo con `Horsepower` es mejor que el modelo sin covariables; el valor-P de la segunda línea es 0.01411, esto indica que es mejor un modelo con las covariables `Horsepower` y `Type`; por último el valor-P de la tercer línea es 0.64803, esto indica que la variable `Weight` no mejora el modelo, es decir, que es mejor un modelo con solo `Horsepower` y `Type`.


## `summary` versus `anova` {-}
La función `summary` permite evaluar el efecto de una variable asumiendo que las restantes variables siguen en el modelo, esto es llamado prueba de hipótesis marginal. Cuando se tiene una variable cualitativa (con $k$ niveles) dentro del modelo, ella aparecerá en la tabla del `summary` por medio de $k-1$ variables indicadoras y por lo tanto se tendrán $k-1$ valores-P asociados. Usar esos valores-P para decidir si una variable cualitativa es importante en el modelo puede ser engañoso, a continuación un ejemplo de esta situación.

### Ejemplo {-}
El ejemplo aquí mostrado está basado [pregunta/respuesta](https://stats.stackexchange.com/questions/115304/interpreting-output-from-anova-when-using-lm-as-input) de StackOverFlow.

El ejemplo consiste en simular un conjunto de 30 valores de $y \sim N(\mu_g, 1)$, donde las observaciones 1 a 10 tienen $mu=0$, las observaciones 11 a 20 tienen $mu=-0.5$ y las restantes diez tienen $mu=0.5$. Para diferenciar las observaciones se tendrá la variable de agruación cualitativa `g` que contendrá las letras A, B y C diez veces cada una. El código para simular los datos se muestra a continuación.

```{r}
set.seed(8867)  # this makes the example exactly reproducible
y <- c(rnorm(10, mean=0,    sd=1),
       rnorm(10, mean=-0.5, sd=1),
       rnorm(10, mean=0.5,  sd=1))
g <- rep(c("A", "B", "C"), each=10)
```

Ahora vamos a ajustar el modelo con fórmula `y ~ g` para estudiar el efecto de la agrupación `g` en la media de la variable respuesta `y`.

```{r}
model <- lm(y ~ g)
```

Obviamente esperamos concluir que la media de la variable `y` dependa de la variable de agrupación `g`. Para esto vamos a explorar el resultado con la función `summary`.

```{r}
summary(model)
```

De la salida anterior vemos que los efectos `gB` y `gC` tienen valores-P altos, superiores al usual 5%, y por lo tanto estaríamos tentados a decir que la variable `g` no tiene efecto sobre la media de `y`. El lector podría encontrar esto puede ser un poco desconcertante.

Vamos a realizar el análisis pero ahora con la función `anova`.

```{r}
anova(model)
```

En la fila donde aparece la variable `g` tenemos el resultado de la prueba de hipótesis

$$H_0: \text{la variable g no influye en la media de y},$$
$$H_A: \text{la variable g si influye en la media de y}$$

El valor-P de esta prueba es de 0.02583, esto indica que hay evidencias para rechazar $H_0$, es decir, encontramos que la variable `g` si influye sobre la media de la variable `y`.

```{block2, type='rmdwarning'}
Cuando se quiera explorar el efecto de una variable cualitativa en un modelo es mejor usar la función `anova` que los resultados del `summary`.
```



